- Optimistic Linear Support and Successor Features as a Basis for Optimal Policy Transfer
- Gradient Based Clustering
- A Natural Actor-Critic Framework for Zero-Sum Markov Games
- Reinforcement Learning from Partial Observation: Linear Function Approximation with Provable Sample Efficiency
- Adaptive Model Design for Markov Decision Process
- EAT-C: Environment-Adversarial sub-Task Curriculum for Efficient Reinforcement Learning
- Safe Learning in Tree-Form Sequential Decision Making: Handling Hard and Soft Constraints
- Near-Optimal Learning of Extensive-Form Games with Imperfect Information
- Congested Bandits: Optimal Routing via Short-term Resets
- Thresholded Lasso Bandit
- Fictitious Play and Best-Response Dynamics in Identical Interest and Zero-Sum Stochastic Games
- Imitation Learning by Estimating Expertise of Demonstrators
- On the Hidden Biases of Policy Mirror Ascent in Continuous Action Spaces
- Stochastic Contextual Dueling Bandits under Linear Stochastic Transitivity Models
- Gradient Descent on Neurons and its Link to Approximate Second-order Optimization
- Optimizing Sequential Experimental Design with Deep Reinforcement Learning
- Interactive Inverse Reinforcement Learning for Cooperative Games
- Near-Optimal Algorithms for Autonomous Exploration and Multi-Goal Stochastic Shortest Path
- A Marriage between Adversarial Team Games and 2-player Games: Enabling Abstractions, No-regret Learning, and Subgame Solving
- Stabilizing Off-Policy Deep Reinforcement Learning from Pixels
- Coarsening the Granularity: Towards Structurally Sparse Lottery Tickets
- Strategies for Safe Multi-Armed Bandits with Logarithmic Regret and Risk
- On the Sample Complexity of Learning Infinite-horizon Discounted Linear Kernel MDPs
- Improved No-Regret Algorithms for Stochastic Shortest Path with Linear MDP
- Learning Infinite-horizon Average-reward Markov Decision Process with Constraints
- Active Multi-Task Representation Learning
- Online Active Regression
- Flow-based Recurrent Belief State Learning for POMDPs
- Auxiliary Learning with Joint Task and Data Scheduling
- Robust Meta-learning with Sampling Noise and Label Noise via Eigen-Reptile
- Efficient Online ML API Selection for Multi-Label Classification Tasks
- Human-in-the-loop: Provably Efficient Preference-based Reinforcement Learning with General Function Approximation
- Sample and Communication-Efficient Decentralized Actor-Critic Algorithms with Finite-Time Analysis
- Adversarially Trained Actor Critic for Offline Reinforcement Learning
- Shuffle Private Linear Contextual Bandits
- Continuous Control with Action Quantization from Demonstrations
- Balancing Sample Efficiency and Suboptimality in Inverse Reinforcement Learning
- Guarantees for Epsilon-Greedy Reinforcement Learning with Function Approximation
- DreamerPro: Reconstruction-Free Model-Based Reinforcement Learning with Prototypical Representations
- Independent Policy Gradient for Large-Scale Markov Potential Games: Sharper Rates, Function Approximation, and Game-Agnostic Convergence
- Branching Reinforcement Learning
- Bayesian Imitation Learning for End-to-End Mobile Manipulation
- DRIBO: Robust Deep Reinforcement Learning via Multi-View Information Bottleneck
- Provable Reinforcement Learning with a Short-Term Memory
- UniRank: Unimodal Bandit Algorithms for Online Ranking
- Achieving Minimax Rates in Pool-Based Batch Active Learning
- A Regret Minimization Approach to Multi-Agent Control
- Blocks Assemble! Learning to Assemble with Large-Scale Structured Reinforcement Learning
- Offline RL Policies Should Be Trained to be Adaptive
- Retrieval-Augmented Reinforcement Learning
- The State of Sparse Training in Deep Reinforcement Learning
- Learning Pseudometric-based Action Representations for Offline Reinforcement Learning
- NeuroFluid: Fluid Dynamics Grounding with Particle-Driven Neural Radiance Fields
- Leveraging Approximate Symbolic Models for Reinforcement Learning via Skill Diversity
- A Parametric Class of Approximate Gradient Updates for Policy Optimization
- Provably Efficient Offline Reinforcement Learning for Partially Observable Markov Decision Processes
- No-Regret Learning in Partially-Informed Auctions
- Online Continual Learning through Mutual Information Maximization
- NISPA: Neuro-Inspired Stability-Plasticity Adaptation for Continual Learning in Sparse Networks
- Active Learning on a Budget: Opposite Strategies Suit High and Low Budgets
- Off-Policy Reinforcement Learning with Delayed Rewards
- Temporal Difference Learning for Model Predictive Control
- Bisimulation Makes Analogies in Goal-Conditioned Reinforcement Learning
- A Reduction from Linear Contextual Bandit Lower Bounds to Estimation Lower Bounds
- Cascaded Gaps: Towards Logarithmic Regret for Risk-Sensitive Reinforcement Learning
- Fast Population-Based Reinforcement Learning on a Single Machine
- Revisiting Some Common Practices in Cooperative Multi-Agent Reinforcement Learning
- Loss Function Learning for Domain Generalization by Implicit Gradient
- Inverse Contextual Bandits: Learning How Behavior Evolves over Time
- Forward Operator Estimation in Generative Models with Kernel Transfer Operators
- Revisiting Online Submodular Minimization: Gap-Dependent Regret Bounds, Best of Both Worlds and Adversarial Robustness
- Modeling Strong and Human-Like Gameplay with KL-Regularized Search
- Regret Minimization with Performative Feedback
- Planning with Diffusion for Flexible Behavior Synthesis
- MASER: Multi-Agent Reinforcement Learning with Subgoals Generated from Experience Replay Buffer
- Improving Policy Optimization with Generalist-Specialist Learning
- Optimal Algorithms for Stochastic Multi-Level Compositional Optimization
- The Power of Exploiter: Provable Multi-Agent RL in Large State Spaces
- Choosing Answers in Epsilon-Best-Answer Identification for Linear Bandits
- Lyapunov Density Models: Constraining Distribution Shift in Learning-Based Control
- Forget-free Continual Learning with Winning Subnetworks
- Training OOD Detectors in their Natural Habitats
- Federated Reinforcement Learning: Linear Speedup Under Markovian Sampling
- Rotting Infinitely Many-Armed Bandits
- Curriculum Reinforcement Learning via Constrained Optimal Transport
- Deep Hierarchy in Bandits
- Nearly Minimax Optimal Reinforcement Learning with Linear Function Approximation
- Policy Diagnosis via Measuring Role Diversity in Cooperative Multi-agent RL
- On the Role of Discount Factor in Offline Reinforcement Learning
- Scalable Deep Reinforcement Learning Algorithms for Mean Field Games
- Convergence of Policy Gradient for Entropy Regularized MDPs with Neural Network Approximation in the Mean-Field Regime
- Phasic Self-Imitative Reduction for Sparse-Reward Goal-Conditioned Reinforcement Learning
- Decomposing Temporal High-Order Interactions via Latent ODEs
- Neural Inverse Transform Sampler
- Deconfounded Value Decomposition for Multi-Agent Reinforcement Learning
- PMIC: Improving Multi-Agent Reinforcement Learning with Progressive Mutual Information Collaboration
- Difference Advantage Estimation for Multi-Agent Policy Gradients
- Reducing Variance in Temporal-Difference Value Estimation via Ensemble of Deep Networks
- TSPipe: Learn from Teacher Faster with Pipelines
- Decentralized Online Convex Optimization in Networked Systems
- Constrained Gradient Descent: A Powerful and Principled Evasion Attack Against Neural Networks
- Learning Augmented Binary Search Trees
- Online Nonsubmodular Minimization with Delayed Costs: From Full Information to Bandit Feedback
- Interactively Learning Preference Constraints in Linear Bandits
- Delayed Reinforcement Learning by Imitation
- Distributionally Robust Q-Learning
- Constrained Variational Policy Optimization for Safe Reinforcement Learning
- Equivalence Analysis between Counterfactual Regret Minimization and Online Mirror Descent
- Optimization-Derived Learning with Essential Convergence Analysis of Training and Hyper-training
- Welfare Maximization in Competitive Equilibrium: Reinforcement Learning for Markov Exchange Economy
- REvolveR: Continuous Evolutionary Models for Robot-to-robot Policy Transfer
- Learning Markov Games with Adversarial Opponents: Efficient Algorithms and Fundamental Limits
- On the Impossibility of Learning to Cooperate with Adaptive Partner Strategies in Repeated Games
- Model-Free Opponent Shaping
- Learning Dynamics and Generalization in Deep Reinforcement Learning
- Pessimism meets VCG: Learning Dynamic Mechanism Design via Offline Reinforcement Learning
- Coordinated Attacks against Contextual Bandits: Fundamental Limits and Defense Mechanisms
- Large Batch Experience Replay
- Smoothed Adaptive Weighting for Imbalanced Semi-Supervised Learning: Improve Reliability Against Unknown Distribution Data
- Cooperative Online Learning in Stochastic and Adversarial MDPs
- Goal Misgeneralization in Deep Reinforcement Learning
- SSL Enables Learning from Sparse Rewards in Image-Goal Navigation
- How to Steer Your Adversary: Targeted and Efficient Model Stealing Defenses with Gradient Redirection
- Transformers are Meta-Reinforcement Learners
- Stochastic Rising Bandits
- Minimizing Control for Credit Assignment with Strong Feedback
- A Dynamical System Perspective for Lipschitz Neural Networks
- Learning Stochastic Shortest Path with Linear Function Approximation
- A Simple Reward-free Approach to Constrained Reinforcement Learning
- EqR: Equivariant Representations for Data-Efficient Reinforcement Learning
- Generalized Beliefs for Cooperative AI
- The Importance of Non-Markovianity in Maximum State Entropy Exploration
- Fast Aquatic Swimmer Optimization with Differentiable Projective Dynamics and Neural Network Hydrodynamic Models
- Recurrent Model-Free RL Can Be a Strong Baseline for Many POMDPs
- Optimal Estimation of Policy Gradient via Double Fitted Iteration
- The Primacy Bias in Deep Reinforcement Learning
- Anticorrelated Noise Injection for Improved Generalization
- History Compression via Language Models in Reinforcement Learning
- Plan Better Amid Conservatism: Offline Multi-Agent Reinforcement Learning with Actor Rectification
- The Unsurprising Effectiveness of Pre-Trained Vision Models for Control
- Learning Symmetric Embeddings for Equivariant World Models
- Evolving Curricula with Regret-Based Environment Design
- Align-RUDDER: Learning From Few Demonstrations by Reward Redistribution
- Differentiable Top-k Classification Learning
- Multi-scale Feature Learning Dynamics: Insights for Double Descent
- A Differential Entropy Estimator for Training Neural Networks
- Sample-Efficient Reinforcement Learning with loglog(T) Switching Cost
- Contrastive UCB: Provably Efficient Contrastive Self-Supervised Learning in Online Reinforcement Learning
- Efficiently Learning the Topology and Behavior of a Networked Dynamical System Via Active Queries
- Learning to Infer Structures of Network Games
- Exploiting Independent Instruments: Identification and Distribution Generalization
- Versatile Dueling Bandits: Best-of-both World Analyses for Learning from Relative Preferences
- Optimal and Efficient Dynamic Regret Algorithms for Non-Stationary Dueling Bandits
- Off-Policy Evaluation for Large Action Spaces via Embeddings
- Convergence Rates of Non-Convex Stochastic Gradient Descent Under a Generic Lojasiewicz Condition and Local Smoothness
- Modeling Irregular Time Series with Continuous Recurrent Units
- Improving Robustness against Real-World and Worst-Case Distribution Shifts through Decision Region Quantification
- Symmetric Machine Theory of Mind
- Continuous-Time Modeling of Counterfactual Outcomes Using Neural Controlled Differential Equations
- Reinforcement Learning with Action-Free Pre-Training from Videos
- Efficient Model-based Multi-agent Reinforcement Learning via Optimistic Equilibrium Computation
- AnyMorph: Learning Transferable Polices By Inferring Agent Morphology
- Disentangling Sources of Risk for Distributional Multi-Agent Reinforcement Learning
- Saute RL: Almost Surely Safe Reinforcement Learning Using State Augmentation
- A State-Distribution Matching Approach to Non-Episodic Reinforcement Learning
- Content Addressable Memory Without Catastrophic Forgetting by Heteroassociation with a Fixed Scaffold
- Federated Minimax Optimization: Improved Convergence Analyses and Algorithms
- DNS: Determinantal Point Process Based Neural Network Sampler for Ensemble Reinforcement Learning
- Instance Dependent Regret Analysis of Kernelized Bandits
- Pessimistic Q-Learning for Offline Reinforcement Learning: Towards Optimal Sample Complexity
- A Minimax Learning Approach to Off-Policy Evaluation in Confounded Partially Observable Markov Decision Processes
- Divergence-Regularized Multi-Agent Actor-Critic
- Influence-Augmented Local Simulators: a Scalable Solution for Fast Deep RL in Large Networked Systems
- Do Differentiable Simulators Give Better Policy Gradients? 20668-20696
- Cliff Diving: Exploring Reward Surfaces in Reinforcement Learning Environments
- AGNAS: Attention-Guided Micro and Macro-Architecture Search
- Adaptive Random Walk Gradient Descent for Decentralized Optimization
- MAE-DET: Revisiting Maximum Entropy Principle in Zero-Shot NAS for Efficient Object Detection
- Generalised Policy Improvement with Geometric Policy Composition
- From Dirichlet to Rubin: Optimistic Exploration in RL without Bonuses
- A Temporal-Difference Approach to Policy Gradient Estimation
- Regret Bounds for Stochastic Shortest Path Problems with Linear Function Approximation
- Addressing Optimism Bias in Sequence Modeling for Reinforcement Learning
- Bayesian Nonparametrics for Offline Skill Discovery
- First-Order Regret in Reinforcement Learning with Linear Function Approximation: A Robust Estimation Approach
- Reward-Free RL is No Harder Than Reward-Aware RL in Linear Markov Decision Processes
- Training Characteristic Functions with Reinforcement Learning: XAI-methods play Connect Four
- Safe Exploration for Efficient Policy Evaluation and Comparison
- Greedy based Value Representation for Optimal Coordination in Multi-agent Reinforcement Learning
- Towards Evaluating Adaptivity of Model-Based Reinforcement Learning Methods
- Denoised MDPs: Learning World Models Better Than the World Itself
- Solving Stackelberg Prediction Game with Least Squares Loss via Spherically Constrained Least Squares Reformulation
- The Geometry of Robust Value Functions
- Risk-Averse No-Regret Learning in Online Convex Games
- Model-based Meta Reinforcement Learning using Graph Structured Surrogate Models and Amortized Policy Search
- Three-stage Evolution and Fast Equilibrium for SGD with Non-degerate Critical Points
- Causal Dynamics Learning for Task-Independent State Abstraction
- When Are Linear Stochastic Bandits Attackable? 23254-23273
- DRAGONN: Distributed Randomized Approximate Gradients of Neural Networks
- Finite-Sum Coupled Compositional Stochastic Optimization: Theory and Applications
- Thompson Sampling for Robust Transfer in Multi-Task Bandits
- Individual Reward Assisted Multi-Agent Reinforcement Learning
- Thompson Sampling for (Combinatorial) Pure Exploration
- Policy Gradient Method For Robust Reinforcement Learning
- Koopman Q-learning: Offline Reinforcement Learning via Symmetries of Dynamics
- Distributional Hamilton-Jacobi-Bellman Equations for Continuous-Time Reinforcement Learning
- Delay-Adaptive Step-sizes for Asynchronous Learning
- Understanding Policy Gradient Algorithms: A Sensitivity-Based Approach
- Robust Deep Reinforcement Learning through Bootstrapped Opportunistic Curriculum
- Nearly Optimal Policy Optimization with Stable at Any Time Guarantee
- RetrievalGuard: Provably Robust 1-Nearest Neighbor Image Retrieval
- Last Iterate Risk Bounds of SGD with Decaying Stepsize for Overparameterized Linear Regression
- Robust Policy Learning over Multiple Uncertainty Sets
- A Self-Play Posterior Sampling Algorithm for Zero-Sum Markov Games
- Detached Error Feedback for Distributed SGD with Random Sparsification
- Prompting Decision Transformer for Few-Shot Policy Generalization
- Discriminator-Weighted Offline Imitation Learning from Suboptimal Demonstrations
- Langevin Monte Carlo for Contextual Bandits
- Regularizing a Model-based Policy Stationary Distribution to Stabilize Offline Reinforcement Learning
- Efficient Variance Reduction for Meta-learning
- Linear Bandit Algorithms with Sublinear Time Complexity
- How to Leverage Unlabeled Data in Offline Reinforcement Learning
- Reachability Constrained Reinforcement Learning
- Robust Task Representations for Offline Meta-Reinforcement Learning via Contrastive Learning
- Provable Stochastic Optimization for Global Contrastive Learning: Small Batch Does Not Harm Performance
- Time Is MattEr: Temporal Self-supervision for Video Transformers
- Actor-Critic based Improper Reinforcement Learning
- Stabilizing Q-learning with Linear Architectures for Provable Efficient Learning
- Adaptive Conformal Predictions for Time Series
- PDE-Based Optimal Strategy for Unconstrained Online Learning
- Stochastic Continuous Submodular Maximization: Boosting via Non-oblivious Function
- Beyond Worst-Case Analysis in Stochastic Approximation: Moment Estimation Improves Instance Complexity
- Efficient Reinforcement Learning in Block MDPs: A Model-free Representation Learning approach
- Expression might be enough: representing pressure and demand for reinforcement learning based traffic signal control
- Off-Policy Fitted Q-Evaluation with Differentiable Function Approximators: Z-Estimation and Inference Theory
- No-Regret Learning in Time-Varying Zero-Sum Games
- Dynamic Regret of Online Markov Decision Processes
- Efficient Learning for AlphaZero via Path Consistency
- Online Decision Transformer
- Pessimistic Minimax Value Iteration: Provably Efficient Equilibrium Learning from Offline Datasets
- A Hierarchical Bayesian Approach to Inverse Reinforcement Learning with Symbolic Reward Machines
- Contextual Bandits with Large Action Spaces: Made Practical