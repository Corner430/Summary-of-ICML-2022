- Optimistic Linear Support and Successor Features as a Basis for Optimal Policy Transfer
- Gradient Based Clustering
- A Natural Actor-Critic Framework for Zero-Sum Markov Games
- Reinforcement Learning from Partial Observation: Linear Function Approximation with Provable Sample Efficiency
- Adaptive Model Design for Markov Decision Process
- EAT-C: Environment-Adversarial sub-Task Curriculum for Efficient Reinforcement Learning
- Safe Learning in Tree-Form Sequential Decision Making: Handling Hard and Soft Constraints
- Near-Optimal Learning of Extensive-Form Games with Imperfect Information
- Congested Bandits: Optimal Routing via Short-term Resets
- Thresholded Lasso Bandit
- Fictitious Play and Best-Response Dynamics in Identical Interest and Zero-Sum Stochastic Games
- Imitation Learning by Estimating Expertise of Demonstrators
- On the Hidden Biases of Policy Mirror Ascent in Continuous Action Spaces
- Stochastic Contextual Dueling Bandits under Linear Stochastic Transitivity Models
- Gradient Descent on Neurons and its Link to Approximate Second-order Optimization
- Optimizing Sequential Experimental Design with Deep Reinforcement Learning
- Interactive Inverse Reinforcement Learning for Cooperative Games
- Near-Optimal Algorithms for Autonomous Exploration and Multi-Goal Stochastic Shortest Path
- A Marriage between Adversarial Team Games and 2-player Games: Enabling Abstractions, No-regret Learning, and Subgame Solving
- Stabilizing Off-Policy Deep Reinforcement Learning from Pixels
- Coarsening the Granularity: Towards Structurally Sparse Lottery Tickets
- Strategies for Safe Multi-Armed Bandits with Logarithmic Regret and Risk
- On the Sample Complexity of Learning Infinite-horizon Discounted Linear Kernel MDPs
- Improved No-Regret Algorithms for Stochastic Shortest Path with Linear MDP
- Learning Infinite-horizon Average-reward Markov Decision Process with Constraints
- Active Multi-Task Representation Learning
- Online Active Regression
- Flow-based Recurrent Belief State Learning for POMDPs
- Auxiliary Learning with Joint Task and Data Scheduling
- Robust Meta-learning with Sampling Noise and Label Noise via Eigen-Reptile
- Efficient Online ML API Selection for Multi-Label Classification Tasks
- Human-in-the-loop: Provably Efficient Preference-based Reinforcement Learning with General Function Approximation
- Sample and Communication-Efficient Decentralized Actor-Critic Algorithms with Finite-Time Analysis
- Adversarially Trained Actor Critic for Offline Reinforcement Learning
- Shuffle Private Linear Contextual Bandits
- Continuous Control with Action Quantization from Demonstrations
- Balancing Sample Efficiency and Suboptimality in Inverse Reinforcement Learning
- Guarantees for Epsilon-Greedy Reinforcement Learning with Function Approximation
- DreamerPro: Reconstruction-Free Model-Based Reinforcement Learning with Prototypical Representations
- Independent Policy Gradient for Large-Scale Markov Potential Games: Sharper Rates, Function Approximation, and Game-Agnostic Convergence
- Branching Reinforcement Learning
- Bayesian Imitation Learning for End-to-End Mobile Manipulation
- DRIBO: Robust Deep Reinforcement Learning via Multi-View Information Bottleneck
- Provable Reinforcement Learning with a Short-Term Memory
- UniRank: Unimodal Bandit Algorithms for Online Ranking
- Achieving Minimax Rates in Pool-Based Batch Active Learning
- A Regret Minimization Approach to Multi-Agent Control
- Blocks Assemble! Learning to Assemble with Large-Scale Structured Reinforcement Learning
- Offline RL Policies Should Be Trained to be Adaptive
- Retrieval-Augmented Reinforcement Learning
- The State of Sparse Training in Deep Reinforcement Learning
- Learning Pseudometric-based Action Representations for Offline Reinforcement Learning
- NeuroFluid: Fluid Dynamics Grounding with Particle-Driven Neural Radiance Fields
- Leveraging Approximate Symbolic Models for Reinforcement Learning via Skill Diversity
- A Parametric Class of Approximate Gradient Updates for Policy Optimization
- Provably Efficient Offline Reinforcement Learning for Partially Observable Markov Decision Processes
- No-Regret Learning in Partially-Informed Auctions
- Online Continual Learning through Mutual Information Maximization
- NISPA: Neuro-Inspired Stability-Plasticity Adaptation for Continual Learning in Sparse Networks
- Active Learning on a Budget: Opposite Strategies Suit High and Low Budgets
- Off-Policy Reinforcement Learning with Delayed Rewards
- Temporal Difference Learning for Model Predictive Control
- Bisimulation Makes Analogies in Goal-Conditioned Reinforcement Learning
- A Reduction from Linear Contextual Bandit Lower Bounds to Estimation Lower Bounds
- Cascaded Gaps: Towards Logarithmic Regret for Risk-Sensitive Reinforcement Learning
- Fast Population-Based Reinforcement Learning on a Single Machine
- Revisiting Some Common Practices in Cooperative Multi-Agent Reinforcement Learning
- Loss Function Learning for Domain Generalization by Implicit Gradient
- Inverse Contextual Bandits: Learning How Behavior Evolves over Time
- Forward Operator Estimation in Generative Models with Kernel Transfer Operators
- Revisiting Online Submodular Minimization: Gap-Dependent Regret Bounds, Best of Both Worlds and Adversarial Robustness
- Modeling Strong and Human-Like Gameplay with KL-Regularized Search
- Regret Minimization with Performative Feedback
- Planning with Diffusion for Flexible Behavior Synthesis
- MASER: Multi-Agent Reinforcement Learning with Subgoals Generated from Experience Replay Buffer
- Improving Policy Optimization with Generalist-Specialist Learning
- Optimal Algorithms for Stochastic Multi-Level Compositional Optimization
- The Power of Exploiter: Provable Multi-Agent RL in Large State Spaces
- Choosing Answers in Epsilon-Best-Answer Identification for Linear Bandits
- Lyapunov Density Models: Constraining Distribution Shift in Learning-Based Control
- Forget-free Continual Learning with Winning Subnetworks
- Training OOD Detectors in their Natural Habitats
- Federated Reinforcement Learning: Linear Speedup Under Markovian Sampling
- Rotting Infinitely Many-Armed Bandits
- Curriculum Reinforcement Learning via Constrained Optimal Transport
- Deep Hierarchy in Bandits
- Nearly Minimax Optimal Reinforcement Learning with Linear Function Approximation
- Policy Diagnosis via Measuring Role Diversity in Cooperative Multi-agent RL
- On the Role of Discount Factor in Offline Reinforcement Learning
- Scalable Deep Reinforcement Learning Algorithms for Mean Field Games
- Convergence of Policy Gradient for Entropy Regularized MDPs with Neural Network Approximation in the Mean-Field Regime
- Phasic Self-Imitative Reduction for Sparse-Reward Goal-Conditioned Reinforcement Learning
- Decomposing Temporal High-Order Interactions via Latent ODEs
- Neural Inverse Transform Sampler
- Deconfounded Value Decomposition for Multi-Agent Reinforcement Learning
- PMIC: Improving Multi-Agent Reinforcement Learning with Progressive Mutual Information Collaboration
- Difference Advantage Estimation for Multi-Agent Policy Gradients
- Reducing Variance in Temporal-Difference Value Estimation via Ensemble of Deep Networks
- TSPipe: Learn from Teacher Faster with Pipelines
- Decentralized Online Convex Optimization in Networked Systems
- Constrained Gradient Descent: A Powerful and Principled Evasion Attack Against Neural Networks
- Learning Augmented Binary Search Trees
- Online Nonsubmodular Minimization with Delayed Costs: From Full Information to Bandit Feedback
- Interactively Learning Preference Constraints in Linear Bandits
- Delayed Reinforcement Learning by Imitation
- Distributionally Robust Q-Learning
- Constrained Variational Policy Optimization for Safe Reinforcement Learning
- Equivalence Analysis between Counterfactual Regret Minimization and Online Mirror Descent
- Optimization-Derived Learning with Essential Convergence Analysis of Training and Hyper-training
- Welfare Maximization in Competitive Equilibrium: Reinforcement Learning for Markov Exchange Economy
- REvolveR: Continuous Evolutionary Models for Robot-to-robot Policy Transfer
- Learning Markov Games with Adversarial Opponents: Efficient Algorithms and Fundamental Limits
- On the Impossibility of Learning to Cooperate with Adaptive Partner Strategies in Repeated Games
- Model-Free Opponent Shaping
- Learning Dynamics and Generalization in Deep Reinforcement Learning
- Pessimism meets VCG: Learning Dynamic Mechanism Design via Offline Reinforcement Learning
- Coordinated Attacks against Contextual Bandits: Fundamental Limits and Defense Mechanisms
- Large Batch Experience Replay
- Smoothed Adaptive Weighting for Imbalanced Semi-Supervised Learning: Improve Reliability Against Unknown Distribution Data
- Cooperative Online Learning in Stochastic and Adversarial MDPs
- Goal Misgeneralization in Deep Reinforcement Learning
- SSL Enables Learning from Sparse Rewards in Image-Goal Navigation
- How to Steer Your Adversary: Targeted and Efficient Model Stealing Defenses with Gradient Redirection
- Transformers are Meta-Reinforcement Learners
- Stochastic Rising Bandits
- Minimizing Control for Credit Assignment with Strong Feedback
- A Dynamical System Perspective for Lipschitz Neural Networks
- Learning Stochastic Shortest Path with Linear Function Approximation
- A Simple Reward-free Approach to Constrained Reinforcement Learning
- EqR: Equivariant Representations for Data-Efficient Reinforcement Learning
- Generalized Beliefs for Cooperative AI
- The Importance of Non-Markovianity in Maximum State Entropy Exploration
- Fast Aquatic Swimmer Optimization with Differentiable Projective Dynamics and Neural Network Hydrodynamic Models
- Recurrent Model-Free RL Can Be a Strong Baseline for Many POMDPs
- Optimal Estimation of Policy Gradient via Double Fitted Iteration
- The Primacy Bias in Deep Reinforcement Learning
- Anticorrelated Noise Injection for Improved Generalization
- History Compression via Language Models in Reinforcement Learning
- Plan Better Amid Conservatism: Offline Multi-Agent Reinforcement Learning with Actor Rectification
- The Unsurprising Effectiveness of Pre-Trained Vision Models for Control
- Learning Symmetric Embeddings for Equivariant World Models
- Evolving Curricula with Regret-Based Environment Design
- Align-RUDDER: Learning From Few Demonstrations by Reward Redistribution
- Differentiable Top-k Classification Learning
- Multi-scale Feature Learning Dynamics: Insights for Double Descent
- A Differential Entropy Estimator for Training Neural Networks
- Sample-Efficient Reinforcement Learning with loglog(T) Switching Cost
- Contrastive UCB: Provably Efficient Contrastive Self-Supervised Learning in Online Reinforcement Learning
- Efficiently Learning the Topology and Behavior of a Networked Dynamical System Via Active Queries
- Learning to Infer Structures of Network Games
- Exploiting Independent Instruments: Identification and Distribution Generalization
- Versatile Dueling Bandits: Best-of-both World Analyses for Learning from Relative Preferences
- Optimal and Efficient Dynamic Regret Algorithms for Non-Stationary Dueling Bandits
- Off-Policy Evaluation for Large Action Spaces via Embeddings
- Convergence Rates of Non-Convex Stochastic Gradient Descent Under a Generic Lojasiewicz Condition and Local Smoothness
- Modeling Irregular Time Series with Continuous Recurrent Units
- Improving Robustness against Real-World and Worst-Case Distribution Shifts through Decision Region Quantification
- Symmetric Machine Theory of Mind
- Continuous-Time Modeling of Counterfactual Outcomes Using Neural Controlled Differential Equations
- Reinforcement Learning with Action-Free Pre-Training from Videos
- Efficient Model-based Multi-agent Reinforcement Learning via Optimistic Equilibrium Computation